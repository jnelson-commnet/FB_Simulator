{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys #Module to access the computer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set paths\n",
    "homey = os.getcwd()\n",
    "redouxPath = os.path.join(homey, 'ForecastRedoux')\n",
    "sqlPath = os.path.join(redouxPath, 'SQL')\n",
    "rawDataPath = os.path.join(redouxPath, 'RawData')\n",
    "AdditionalInfoPath = os.path.join(homey, 'AdditionalInfo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to FB API\n",
    "sys.path.insert(0, 'Z:\\Python projects\\FishbowlAPITestProject')\n",
    "import connecttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myresults = connecttest.create_connection(sqlPath, 'BOMQuery.txt')\n",
    "myexcel = connecttest.makeexcelsheet(myresults)\n",
    "connecttest.save_workbook(myexcel, rawDataPath, 'BOMs.xlsx')\n",
    "myresults = connecttest.create_connection(sqlPath, 'PartQuery.txt')\n",
    "myexcel = connecttest.makeexcelsheet(myresults)\n",
    "connecttest.save_workbook(myexcel, rawDataPath, 'Parts.xlsx')\n",
    "myresults = connecttest.create_connection(sqlPath, 'MOQueryRedouxAlternate.txt')\n",
    "myexcel = connecttest.makeexcelsheet(myresults)\n",
    "connecttest.save_workbook(myexcel, rawDataPath, 'MOs.xlsx')\n",
    "myresults = connecttest.create_connection(sqlPath, 'POQueryAlternate.txt')\n",
    "myexcel = connecttest.makeexcelsheet(myresults)\n",
    "connecttest.save_workbook(myexcel, rawDataPath, 'POs.xlsx')\n",
    "myresults = connecttest.create_connection(sqlPath, 'SOQueryAlternate.txt')\n",
    "myexcel = connecttest.makeexcelsheet(myresults)\n",
    "connecttest.save_workbook(myexcel, rawDataPath, 'SOs.xlsx')\n",
    "myresults = connecttest.create_connection(sqlPath, 'INVQueryAlternate.txt')\n",
    "myexcel = connecttest.makeexcelsheet(myresults)\n",
    "connecttest.save_workbook(myexcel, rawDataPath, 'INVs.xlsx')\n",
    "myresults = connecttest.create_connection(sqlPath, 'DescQuery.txt')\n",
    "myexcel = connecttest.makeexcelsheet(myresults)\n",
    "connecttest.save_workbook(myexcel, rawDataPath, 'Descs.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, redouxPath) #Pull up the file with the forecast information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ForecastMain #Import the actual forecast python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ForecastMain.run_normal_forecast_tiers_v2(\n",
    "    ignore_schedule_errors=True, \n",
    "    add_stock_builds=False, \n",
    "    ignore_orders=False, \n",
    "    sql_queries=False\n",
    ") #Run the actual forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pull in most recent timeline\n",
    "timeline = pd.read_excel(os.path.join(homey, 'RegularForecast.xlsx'), sheet_name='Timeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Query part costs\n",
    "myresults = connecttest.create_connection(sqlPath, 'AvgCostQuery.txt')\n",
    "myexcel = connecttest.makeexcelsheet(myresults)\n",
    "connecttest.save_workbook(myexcel, rawDataPath, 'AvgCosts.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get part costs into a dataFrame\n",
    "costpath = os.path.join(rawDataPath, 'AvgCosts.xlsx')\n",
    "avgCost = pd.read_excel(costpath) #Opens and puts the data into a dataframe\n",
    "avgCost = avgCost.sort_values(by='PART', ascending=True) #Sort the data by part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge part costs onto timeline\n",
    "timeline = pd.merge(timeline.copy(), avgCost.copy(), how='left', on='PART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate total costs\n",
    "timeline['TotalCost'] = timeline['QTYREMAINING'] * timeline['AvgCost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Grab list of imaginary builds and create build number reference\n",
    "newbuilds = pd.read_excel(os.path.join(AdditionalInfoPath, 'PartsToBuild.xlsx'), sheetname='Sheet1')\n",
    "newbuilds.reset_index(inplace=True)\n",
    "newbuilds['buildIndex'] = (newbuilds['index'] * -1) -1\n",
    "newbuilds.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create columns to be filled by the next loop.\n",
    "newbuilds['Total_Purchase'] = 0\n",
    "newbuilds['Material_Cost'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# This dataFrame will hold cost issues for all the imaginary builds\n",
    "missingCost = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\"\"\" This loop calculates and updates the total purchasing need for each imaginary build\n",
    "    and it also finds the total raw material cost. \"\"\"\n",
    "for index, row in newbuilds.iterrows():\n",
    "    imagBuild = row['buildIndex']\n",
    "    thisBuild = timeline[timeline['GRANDPARENT'] == imagBuild].copy()\n",
    "    purchDF = thisBuild[thisBuild['ORDERTYPE'] == 'Purchase'].copy()\n",
    "    totPurchDF = purchDF[purchDF['TotalCost'].notnull()].copy()\n",
    "    newbuilds.set_value(index, 'Total_Purchase', purchDF['TotalCost'].sum())\n",
    "    # Now adding the total raw good cost of \"Buy\" items to show total amount in movement\n",
    "    buyItemsDF = thisBuild[thisBuild['Make/Buy'] == 'Buy'].copy()\n",
    "    rawGoodsDF = buyItemsDF[buyItemsDF['ORDERTYPE'] == 'Raw Good']\n",
    "    newbuilds.set_value(index, 'Material_Cost', -1*(rawGoodsDF['TotalCost'].sum()))\n",
    "    # missingCost records parts that have 0 cost or are completely missing cost\n",
    "    noCostDF = rawGoodsDF[(rawGoodsDF['TotalCost'].isnull()) | (rawGoodsDF['TotalCost'] == 0)].copy() # ... it's so nice ...\n",
    "    noCostDF['Build'] = newbuilds.get_value(index, 'Part')\n",
    "    missingCost = missingCost.copy().append(noCostDF.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create a column representing cost in material either in inventory currently or already on order\n",
    "newbuilds['Current_Cost_Used'] = newbuilds['Material_Cost'] - newbuilds['Total_Purchase']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Generic labor estimate based solely on total material cost of the build\n",
    "newbuilds['Labor_Estimate'] = newbuilds['Material_Cost'] * 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cost including materials and labor estimate\n",
    "newbuilds['Total_Cost'] = newbuilds['Material_Cost'] + newbuilds['Labor_Estimate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "timeline.to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "newbuilds.to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "missingCost.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "newbuilds.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "missingCost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "timeline.to_clipboard(excel=True, sep=\"comma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "to_clipboard() stopped working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(os.path.join(homey, 'BuildCostResults.xlsx'))  # Creates a test excel file\n",
    "timeline.to_excel(writer, 'timeline', index=False)  # Fills the test excel with the whole timeline\n",
    "# newbuilds.to_excel(writer, 'newbuilds', index=False)\n",
    "# missingCost.to_excel(writer, 'missingCost', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is checking inventory cost for backlog or something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Query part costs\n",
    "myresults = connecttest.create_connection(sqlPath, 'AssetQuery.txt')\n",
    "myexcel = connecttest.makeexcelsheet(myresults)\n",
    "connecttest.save_workbook(myexcel, rawDataPath, 'Asset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assetpath = os.path.join(rawDataPath, 'Asset.xlsx')\n",
    "asset = pd.read_excel(assetpath) #Opens and puts the data into a dataframe\n",
    "asset = asset.sort_values(by='PART', ascending=True) #Sort the data by part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assettypepath = os.path.join(rawDataPath, 'AssetByType.xlsx')\n",
    "typeAsset = pd.read_excel(assettypepath) #Opens and puts the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asset = pd.merge(asset.copy(), typeAsset.copy(), how='left', on='ASSET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# theoretically this is the total cost of everything that we don't have but need to fill the backlog.  Some currently issued POs would count toward this.\n",
    "timeline['TotalCost'][timeline['ORDERTYPE'] == 'Purchase'].copy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "footy = timeline.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "startInv = footy.drop_duplicates('PART', keep='first').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "endInv = footy.drop_duplicates('PART', keep='last').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "startInv['STARTINV'] = startInv['INV'].copy()\n",
    "endInv['ENDINV'] = endInv['INV'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doots = pd.merge(startInv.copy(), endInv[['PART','ENDINV']].copy(), how='left', on='PART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doots = doots[['PART','STARTINV','ENDINV']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "invpath = os.path.join(rawDataPath, 'INVs.xlsx')\n",
    "origInv = pd.read_excel(invpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "origInv.rename({'INV':'STARTINV'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "origInv['ENDINV'] = origInv['STARTINV'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doots = doots.copy().append(origInv.copy(), sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doots.drop_duplicates('PART', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doots['INVUSED'] = doots['STARTINV'].copy() - doots['ENDINV'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doots = pd.merge(doots.copy(), avgCost.copy(), how='left', on='PART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "doots['USEDTOTALCOST'] = doots['INVUSED'].copy() * doots['AvgCost'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doots['STARTTOTALCOST'] = doots['STARTINV'].copy() * doots['AvgCost'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doots['ENDTOTALCOST'] = doots['ENDINV'].copy() * doots['AvgCost'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doots = pd.merge(doots.copy(), asset.copy(), how='left', on='PART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(os.path.join(homey, 'doots.xlsx'))  # Creates a test excel file\n",
    "doots.to_excel(writer, 'timeline', index=False)  # Fills the test excel with the whole timeline\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mfgDoots = doots[doots['TYPE'] == 'MFG'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "integDoots = doots[doots['TYPE'] == 'INTEG'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mfgDoots['USEDTOTALCOST'][mfgDoots['INVUSED'] > 0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mfgDoots['STARTTOTALCOST'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mfgDoots['ENDTOTALCOST'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mfgDoots['USEDTOTALCOST'].sum() + mfgDoots['ENDTOTALCOST'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mfgDoots['USEDTOTALCOST'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Query part costs\n",
    "myresults = connecttest.create_connection(sqlPath, 'InvCostLayerQuery.txt')\n",
    "myexcel = connecttest.makeexcelsheet(myresults)\n",
    "connecttest.save_workbook(myexcel, rawDataPath, 'InvCostLayer.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "costLayerPath = os.path.join(rawDataPath, 'InvCostLayer.xlsx')\n",
    "costLayer = pd.read_excel(costLayerPath) #Opens and puts the data into a dataframe\n",
    "costLayer = costLayer.sort_values(by='PART', ascending=True) #Sort the data by part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inv2018 = costLayer[['PART','2018INV']].copy().groupby('PART').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statime = pd.merge(doots.copy(), inv2018.copy(), how='left', on='PART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statime.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statime.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statime['STALESTART'] = 0\n",
    "statime['FRESHSTART'] = 0\n",
    "statime['STALEUSED'] = 0\n",
    "statime['FRESHUSED'] = 0\n",
    "statime['STALEEND'] = 0\n",
    "statime['FRESHEND'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index in statime.index:\n",
    "    if statime['2018INV'].at[index] >= statime['ENDINV'].at[index]:\n",
    "        statime['FRESHEND'].at[index] = statime['ENDINV'].at[index]\n",
    "        statime['STALEEND'].at[index] = 0\n",
    "    else:\n",
    "        statime['FRESHEND'].at[index] = statime['2018INV'].at[index]\n",
    "        statime['STALEEND'].at[index] = statime['ENDINV'].at[index] - statime['2018INV'].at[index]\n",
    "    if statime['2018INV'].at[index] >= statime['STARTINV'].at[index]:\n",
    "        statime['FRESHSTART'].at[index] = statime['STARTINV'].at[index]\n",
    "        statime['STALESTART'].at[index] = 0\n",
    "    else:\n",
    "        statime['FRESHSTART'].at[index] = statime['2018INV'].at[index]\n",
    "        statime['STALESTART'].at[index] = statime['STARTINV'].at[index] - statime['2018INV'].at[index]\n",
    "    statime['STALEUSED'].at[index] = statime['STALESTART'].at[index] - statime['STALEEND'].at[index]\n",
    "    statime['FRESHUSED'].at[index] = statime['FRESHSTART'].at[index] - statime['FRESHEND'].at[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "partspath = os.path.join(rawDataPath, 'Parts.xlsx')\n",
    "parts = pd.read_excel(partspath) #Opens and puts the data into a dataframe\n",
    "parts = parts.sort_values(by='PART', ascending=True) #Sort the data by part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statime = pd.merge(statime.copy(), parts[['PART','Make/Buy']].copy(), how='left', on='PART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desc = pd.read_excel(os.path.join(rawDataPath, 'Descs.xlsx'), header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statime = pd.merge(statime.copy(), desc.copy(), how='left', on='PART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statime['STALESTARTVAL'] = statime['STALESTART'].copy() * statime['AvgCost'].copy()\n",
    "statime['FRESHSTARTVAL'] = statime['FRESHSTART'].copy() * statime['AvgCost'].copy()\n",
    "statime['STALEUSEDVAL'] = statime['STALEUSED'].copy() * statime['AvgCost'].copy()\n",
    "statime['FRESHUSEDVAL'] = statime['FRESHUSED'].copy() * statime['AvgCost'].copy()\n",
    "statime['STALEENDVAL'] = statime['STALEEND'].copy() * statime['AvgCost'].copy()\n",
    "statime['FRESHENDVAL'] = statime['FRESHEND'].copy() * statime['AvgCost'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headerStatime = ['PART','DESCRIPTION','STARTINV','STARTTOTALCOST','ENDINV','ENDTOTALCOST','INVUSED','USEDTOTALCOST','STALESTART','STALESTARTVAL','FRESHSTART','FRESHSTARTVAL','STALEUSED','STALEUSEDVAL','FRESHUSED','FRESHUSEDVAL','STALEEND','STALEENDVAL','FRESHEND','FRESHENDVAL','AvgCost','ASSET','TYPE','2018INV','Make/Buy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statime = statime[headerStatime].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(os.path.join(homey, 'statime.xlsx'))  # Creates a test excel file\n",
    "statime.to_excel(writer, 'timeline', index=False)  # Fills the test excel with the whole timeline\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statime"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
