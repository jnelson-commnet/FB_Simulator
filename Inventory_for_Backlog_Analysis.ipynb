{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys #Module to access the computer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set paths\n",
    "homey = os.getcwd()\n",
    "redouxPath = os.path.join(homey, 'ForecastRedoux')\n",
    "sqlPath = os.path.join(redouxPath, 'SQL')\n",
    "rawDataPath = os.path.join(redouxPath, 'RawData')\n",
    "AdditionalInfoPath = os.path.join(homey, 'AdditionalInfo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to FB API\n",
    "sys.path.insert(0, 'Z:\\Python projects\\FishbowlAPITestProject')\n",
    "import connecttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# myresults = connecttest.create_connection(sqlPath, 'MOQueryRedouxAlternate.txt')\n",
    "# myexcel = connecttest.makeexcelsheet(myresults)\n",
    "# connecttest.save_workbook(myexcel, rawDataPath, 'MOs.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# myresults = connecttest.create_connection(sqlPath, 'INVQueryAlternate.txt')\n",
    "# myexcel = connecttest.makeexcelsheet(myresults)\n",
    "# connecttest.save_workbook(myexcel, rawDataPath, 'INVs.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# myresults = connecttest.create_connection(sqlPath, 'SOQueryAlternate.txt')\n",
    "# myexcel = connecttest.makeexcelsheet(myresults)\n",
    "# connecttest.save_workbook(myexcel, rawDataPath, 'SOs.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# myresults = connecttest.create_connection(sqlPath, 'POQueryAlternate.txt')\n",
    "# myexcel = connecttest.makeexcelsheet(myresults)\n",
    "# connecttest.save_workbook(myexcel, rawDataPath, 'POs.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# myresults = connecttest.create_connection(sqlPath, 'BOMQuery.txt')\n",
    "# myexcel = connecttest.makeexcelsheet(myresults)\n",
    "# connecttest.save_workbook(myexcel, rawDataPath, 'BOMs.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# myresults = connecttest.create_connection(sqlPath, 'PartQuery.txt')\n",
    "# myexcel = connecttest.makeexcelsheet(myresults)\n",
    "# connecttest.save_workbook(myexcel, rawDataPath, 'Parts.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# myresults = connecttest.create_connection(sqlPath, 'DescQuery.txt')\n",
    "# myexcel = connecttest.makeexcelsheet(myresults)\n",
    "# connecttest.save_workbook(myexcel, rawDataPath, 'Descs.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, redouxPath) #Pull up the file with the forecast information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ForecastMain #Import the actual forecast python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# here's an option\n",
    "ForecastMain.run_normal_forecast_tiers_v2(\n",
    "    ignore_schedule_errors=True, \n",
    "    add_stock_builds=True, \n",
    "    ignore_orders=False, \n",
    "    sql_queries=False\n",
    ") #Run the actual forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!Not pulling fresh data from FB!\n",
      "adjusting schedule to avoid issues ...\n",
      "going into create_bom_tiers\n",
      "section 1\n",
      "section 2\n",
      "tier 2 created\n",
      "tier 3 created\n",
      "tier 4 created\n",
      "tier 5 created\n",
      "tier 6 created\n",
      "tier 7 created\n",
      "tier 8 created\n",
      "tier 9 created\n",
      "section 3\n",
      "out of create_bom_tiers\n",
      "Running tier 1\n",
      "Running tier 2\n",
      "Running tier 3\n",
      "Running tier 4\n",
      "Running tier 5\n",
      "Running tier 6\n",
      "Running tier 7\n",
      "Running tier 8\n",
      "Running tier 9\n",
      "Running tier 10\n",
      "*Timeline Has Been Created*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jack\\Documents\\GitHub\\FB_Simulator\\ForecastRedoux\\ForecastTimelineBackend.py:334: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  if parentTemp.get_value(0, 'ITEM') == 'Phantom':\n",
      "C:\\Users\\Jack\\Documents\\GitHub\\FB_Simulator\\ForecastRedoux\\ForecastTimelineBackend.py:341: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  elif parentTemp.get_value(0, 'ITEM') == 'Imaginary':\n",
      "C:\\Users\\Jack\\Documents\\GitHub\\FB_Simulator\\ForecastRedoux\\ForecastTimelineBackend.py:355: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  rowp = parentTemp.get_value(0, 'PARENT')\n",
      "C:\\Users\\Jack\\Documents\\GitHub\\FB_Simulator\\ForecastRedoux\\ForecastTimelineBackend.py:367: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  if parentTemp.get_value(0, 'ORDERTYPE') == 'Raw Good':\n",
      "C:\\Users\\Jack\\Documents\\GitHub\\FB_Simulator\\ForecastRedoux\\ForecastTimelineBackend.py:371: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  if parentTemp.get_value(0, 'ITEM') == 'Phantom':\n",
      "C:\\Users\\Jack\\Documents\\GitHub\\FB_Simulator\\ForecastRedoux\\ForecastTimelineBackend.py:372: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  secondTempHold = timeline.ix[timeline['ORDER'] == parentTemp.get_value(0, 'PARENT')]\n",
      "C:\\Users\\Jack\\Documents\\GitHub\\FB_Simulator\\ForecastRedoux\\ForecastTimelineBackend.py:373: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  parentTemp = secondTempHold.ix[secondTempHold['PART'] == parentTemp.get_value(0, 'PART')]\n",
      "C:\\Users\\Jack\\Documents\\GitHub\\FB_Simulator\\ForecastRedoux\\ForecastTimelineBackend.py:368: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  secondTempHold = timeline.ix[timeline['ORDER'] == parentTemp.get_value(0, 'ORDER')]\n",
      "C:\\Users\\Jack\\Documents\\GitHub\\FB_Simulator\\ForecastRedoux\\ForecastTimelineBackend.py:374: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  elif parentTemp.get_value(0, 'ITEM') == 'Imaginary':\n",
      "C:\\Users\\Jack\\Documents\\GitHub\\FB_Simulator\\ForecastRedoux\\ForecastTimelineBackend.py:382: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  timeline.ix[index, 'GRANDPARENT'] = parentTemp.get_value(0, 'PARENT')\n",
      "C:\\Users\\Jack\\Documents\\GitHub\\FB_Simulator\\ForecastRedoux\\ForecastTimelineBackend.py:335: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  if parentTemp.get_value(0, 'ORDERTYPE') == 'Raw Good':\n",
      "C:\\Users\\Jack\\Documents\\GitHub\\FB_Simulator\\ForecastRedoux\\ForecastTimelineBackend.py:336: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  secondTempHold = timeline.ix[timeline['ORDER'] == parentTemp.get_value(0, 'ORDER')]\n",
      "C:\\Users\\Jack\\Documents\\GitHub\\FB_Simulator\\ForecastRedoux\\ForecastTimelineBackend.py:339: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  secondTempHold = timeline.ix[timeline['ORDER'] == parentTemp.get_value(0, 'PARENT')]\n",
      "C:\\Users\\Jack\\Documents\\GitHub\\FB_Simulator\\ForecastRedoux\\ForecastTimelineBackend.py:340: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  parentTemp = secondTempHold.ix[secondTempHold['PART'] == parentTemp.get_value(0, 'PART')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved mytimelinetest.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jack\\Documents\\GitHub\\FB_Simulator\\ForecastRedoux\\ForecastTimelineBackend.py:524: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  tempdf.set_value(index=0, col='INV', value= tempdf['INV'].iloc[1])  # this references the inventory on the other columns to set the starting inventory\n",
      "C:\\Users\\Jack\\Documents\\GitHub\\FB_Simulator\\ForecastRedoux\\ForecastTimelineBackend.py:527: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  tempdf.set_value(ind, 'INV', (tempdf['INV'].iloc[ind-1] + tempdf['QTYREMAINING'].iloc[ind]))  # set the next inventory value by adding the order amount to the previous inventory value\n",
      "C:\\Users\\Jack\\Documents\\GitHub\\FB_Simulator\\ForecastRedoux\\ForecastTimelineBackend.py:408: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  value = tempAdf.get_value(rowcountb, each)\n",
      "C:\\Users\\Jack\\Documents\\GitHub\\FB_Simulator\\ForecastRedoux\\ForecastTimelineBackend.py:417: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  description = tempAdf.get_value(0, 'DESCRIPTION') # pull Part description from inital row\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtotal sheets created ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jack\\Documents\\GitHub\\FB_Simulator\\ForecastRedoux\\ForecastTimelineBackend.py:471: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  value = timeline.get_value(row-1, column, True)\n",
      "C:\\Users\\Jack\\Documents\\GitHub\\FB_Simulator\\ForecastRedoux\\ForecastTimelineBackend.py:468: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  value = timeline.get_value(row-1, column, True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workbook closed\n",
      "*The forecast is done!*\n"
     ]
    }
   ],
   "source": [
    "# here's another\n",
    "\n",
    "ForecastMain.run_normal_forecast_tiers_v2(\n",
    "    ignore_schedule_errors=True, \n",
    "    add_stock_builds=False, \n",
    "    ignore_orders=False, \n",
    "    sql_queries=False\n",
    ") #Run the actual forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pull in most recent timeline\n",
    "timeline = pd.read_excel(os.path.join(homey, 'RegularForecast.xlsx'), sheet_name='Timeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# temp commenting out for repetions\n",
    "\n",
    "# Query part costs\n",
    "# myresults = connecttest.create_connection(sqlPath, 'AvgCostQuery.txt')\n",
    "# myexcel = connecttest.makeexcelsheet(myresults)\n",
    "# connecttest.save_workbook(myexcel, rawDataPath, 'AvgCosts.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get part costs into a dataFrame\n",
    "costpath = os.path.join(rawDataPath, 'AvgCosts.xlsx')\n",
    "avgCost = pd.read_excel(costpath) #Opens and puts the data into a dataframe\n",
    "avgCost = avgCost.sort_values(by='PART', ascending=True) #Sort the data by part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge part costs onto timeline\n",
    "timeline = pd.merge(timeline.copy(), avgCost.copy(), how='left', on='PART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate total costs\n",
    "timeline['TotalCost'] = timeline['QTYREMAINING'] * timeline['AvgCost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HEY - The parts after this are for if there are imaginary builds only!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Grab list of imaginary builds and create build number reference\n",
    "newbuilds = pd.read_excel(os.path.join(AdditionalInfoPath, 'PartsToBuild.xlsx'), sheetname='Sheet1')\n",
    "newbuilds.reset_index(inplace=True)\n",
    "newbuilds['buildIndex'] = (newbuilds['index'] * -1) -1\n",
    "newbuilds.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create columns to be filled by the next loop.\n",
    "newbuilds['Total_Purchase'] = 0\n",
    "newbuilds['Material_Cost'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This dataFrame will hold cost issues for all the imaginary builds\n",
    "missingCost = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" This loop calculates and updates the total purchasing need for each imaginary build\n",
    "    and it also finds the total raw material cost. \"\"\"\n",
    "for index, row in newbuilds.iterrows():\n",
    "    imagBuild = row['buildIndex']\n",
    "    thisBuild = timeline[timeline['GRANDPARENT'] == imagBuild].copy()\n",
    "    purchDF = thisBuild[thisBuild['ORDERTYPE'] == 'Purchase'].copy()\n",
    "    totPurchDF = purchDF[purchDF['TotalCost'].notnull()].copy()\n",
    "    newbuilds.set_value(index, 'Total_Purchase', purchDF['TotalCost'].sum())\n",
    "    # Now adding the total raw good cost of \"Buy\" items to show total amount in movement\n",
    "    buyItemsDF = thisBuild[thisBuild['Make/Buy'] == 'Buy'].copy()\n",
    "    rawGoodsDF = buyItemsDF[buyItemsDF['ORDERTYPE'] == 'Raw Good']\n",
    "    newbuilds.set_value(index, 'Material_Cost', -1*(rawGoodsDF['TotalCost'].sum()))\n",
    "    # missingCost records parts that have 0 cost or are completely missing cost\n",
    "    noCostDF = rawGoodsDF[(rawGoodsDF['TotalCost'].isnull()) | (rawGoodsDF['TotalCost'] == 0)].copy() # ... it's so nice ...\n",
    "    noCostDF['Build'] = newbuilds.get_value(index, 'Part')\n",
    "    missingCost = missingCost.copy().append(noCostDF.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a column representing cost in material either in inventory currently or already on order\n",
    "newbuilds['Current_Cost_Used'] = newbuilds['Material_Cost'] - newbuilds['Total_Purchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generic labor estimate based solely on total material cost of the build\n",
    "newbuilds['Labor_Estimate'] = newbuilds['Material_Cost'] * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cost including materials and labor estimate\n",
    "newbuilds['Total_Cost'] = newbuilds['Material_Cost'] + newbuilds['Labor_Estimate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(os.path.join(homey, 'BuildCostResults.xlsx'))  # Creates a test excel file\n",
    "timeline.to_excel(writer, 'timeline', index=False)  # Fills the test excel with the whole timeline\n",
    "newbuilds.to_excel(writer, 'newbuilds', index=False)\n",
    "missingCost.to_excel(writer, 'missingCost', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "HEY - Skip to here if not using imaginary builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is checking inventory cost for backlog or something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#temp commenting out for repetions\n",
    "\n",
    "# Query part costs\n",
    "\n",
    "# myresults = connecttest.create_connection(sqlPath, 'AssetQuery.txt')\n",
    "# myexcel = connecttest.makeexcelsheet(myresults)\n",
    "# connecttest.save_workbook(myexcel, rawDataPath, 'Asset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assetpath = os.path.join(rawDataPath, 'Asset.xlsx')\n",
    "asset = pd.read_excel(assetpath) #Opens and puts the data into a dataframe\n",
    "asset = asset.sort_values(by='PART', ascending=True) #Sort the data by part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assettypepath = os.path.join(rawDataPath, 'AssetByType.xlsx')\n",
    "typeAsset = pd.read_excel(assettypepath) #Opens and puts the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asset = pd.merge(asset.copy(), typeAsset.copy(), how='left', on='ASSET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1397204.847955696"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# theoretically this is the total cost of everything that we don't have but need to fill the backlog.  Some currently issued POs would count toward this.\n",
    "# only applies if ignoring current PO lines in report\n",
    "timeline['TotalCost'][timeline['ORDERTYPE'] == 'Purchase'].copy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "footy = timeline.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "startInv = footy.drop_duplicates('PART', keep='first').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "endInv = footy.drop_duplicates('PART', keep='last').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "startInv['STARTINV'] = startInv['INV'].copy()\n",
    "endInv['ENDINV'] = endInv['INV'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doots = pd.merge(startInv.copy(), endInv[['PART','ENDINV']].copy(), how='left', on='PART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doots = doots[['PART','STARTINV','ENDINV']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "invpath = os.path.join(rawDataPath, 'INVs.xlsx')\n",
    "origInv = pd.read_excel(invpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "origInv.rename({'INV':'STARTINV'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "origInv['ENDINV'] = origInv['STARTINV'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doots = doots.copy().append(origInv.copy(), sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doots.drop_duplicates('PART', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doots['INVUSED'] = doots['STARTINV'].copy() - doots['ENDINV'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doots = pd.merge(doots.copy(), avgCost.copy(), how='left', on='PART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "doots['USEDTOTALCOST'] = doots['INVUSED'].copy() * doots['AvgCost'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doots['STARTTOTALCOST'] = doots['STARTINV'].copy() * doots['AvgCost'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doots['ENDTOTALCOST'] = doots['ENDINV'].copy() * doots['AvgCost'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doots = pd.merge(doots.copy(), asset.copy(), how='left', on='PART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(os.path.join(homey, 'doots.xlsx'))  # Creates a test excel file\n",
    "doots.to_excel(writer, 'timeline', index=False)  # Fills the test excel with the whole timeline\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mfgDoots = doots[doots['TYPE'] == 'MFG'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "integDoots = doots[doots['TYPE'] == 'INTEG'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mfgDoots['USEDTOTALCOST'][mfgDoots['INVUSED'] > 0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mfgDoots['STARTTOTALCOST'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mfgDoots['ENDTOTALCOST'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mfgDoots['USEDTOTALCOST'].sum() + mfgDoots['ENDTOTALCOST'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mfgDoots['USEDTOTALCOST'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# temp commenting out for repetition\n",
    "# Query cost layer\n",
    "\n",
    "# myresults = connecttest.create_connection(sqlPath, 'InvCostLayerQuery.txt')\n",
    "# myexcel = connecttest.makeexcelsheet(myresults)\n",
    "# connecttest.save_workbook(myexcel, rawDataPath, 'InvCostLayer.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "costLayerPath = os.path.join(rawDataPath, 'InvCostLayer.xlsx')\n",
    "costLayer = pd.read_excel(costLayerPath) #Opens and puts the data into a dataframe\n",
    "costLayer = costLayer.sort_values(by='PART', ascending=True) #Sort the data by part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inv2018 = costLayer[['PART','2018INV']].copy().groupby('PART').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statime = pd.merge(doots.copy(), inv2018.copy(), how='left', on='PART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statime.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statime.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statime['STALESTART'] = 0\n",
    "statime['FRESHSTART'] = 0\n",
    "statime['STALEUSED'] = 0\n",
    "statime['FRESHUSED'] = 0\n",
    "statime['STALEEND'] = 0\n",
    "statime['FRESHEND'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# statime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index in statime.index:\n",
    "    if statime['2018INV'].at[index] >= statime['ENDINV'].at[index]:\n",
    "        statime['FRESHEND'].at[index] = statime['ENDINV'].at[index]\n",
    "        statime['STALEEND'].at[index] = 0\n",
    "    else:\n",
    "        statime['FRESHEND'].at[index] = statime['2018INV'].at[index]\n",
    "        statime['STALEEND'].at[index] = statime['ENDINV'].at[index] - statime['2018INV'].at[index]\n",
    "    if statime['2018INV'].at[index] >= statime['STARTINV'].at[index]:\n",
    "        statime['FRESHSTART'].at[index] = statime['STARTINV'].at[index]\n",
    "        statime['STALESTART'].at[index] = 0\n",
    "    else:\n",
    "        statime['FRESHSTART'].at[index] = statime['2018INV'].at[index]\n",
    "        statime['STALESTART'].at[index] = statime['STARTINV'].at[index] - statime['2018INV'].at[index]\n",
    "    statime['STALEUSED'].at[index] = statime['STALESTART'].at[index] - statime['STALEEND'].at[index]\n",
    "    statime['FRESHUSED'].at[index] = statime['FRESHSTART'].at[index] - statime['FRESHEND'].at[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "partspath = os.path.join(rawDataPath, 'Parts.xlsx')\n",
    "parts = pd.read_excel(partspath) #Opens and puts the data into a dataframe\n",
    "parts = parts.sort_values(by='PART', ascending=True) #Sort the data by part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statime = pd.merge(statime.copy(), parts[['PART','Make/Buy']].copy(), how='left', on='PART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desc = pd.read_excel(os.path.join(rawDataPath, 'Descs.xlsx'), header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statime = pd.merge(statime.copy(), desc.copy(), how='left', on='PART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statime['STALESTARTVAL'] = statime['STALESTART'].copy() * statime['AvgCost'].copy()\n",
    "statime['FRESHSTARTVAL'] = statime['FRESHSTART'].copy() * statime['AvgCost'].copy()\n",
    "statime['STALEUSEDVAL'] = statime['STALEUSED'].copy() * statime['AvgCost'].copy()\n",
    "statime['FRESHUSEDVAL'] = statime['FRESHUSED'].copy() * statime['AvgCost'].copy()\n",
    "statime['STALEENDVAL'] = statime['STALEEND'].copy() * statime['AvgCost'].copy()\n",
    "statime['FRESHENDVAL'] = statime['FRESHEND'].copy() * statime['AvgCost'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headerStatime = ['PART','DESCRIPTION','STARTINV','STARTTOTALCOST','ENDINV','ENDTOTALCOST','INVUSED','USEDTOTALCOST','STALESTART','STALESTARTVAL','FRESHSTART','FRESHSTARTVAL','STALEUSED','STALEUSEDVAL','FRESHUSED','FRESHUSEDVAL','STALEEND','STALEENDVAL','FRESHEND','FRESHENDVAL','AvgCost','ASSET','TYPE','2018INV','Make/Buy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statime = statime[headerStatime].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(os.path.join(homey, 'statime.xlsx'))  # Creates a test excel file\n",
    "statime.to_excel(writer, 'timeline', index=False)  # Fills the test excel with the whole timeline\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
